{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":300384,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":256592,"modelId":277921}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Week_10_Point_Clouds\nTime capacity 3 $\\pm$ 0.5 hours\n\nby \"First name\" \"Second name\"\n\n\"Month, Day, 2025\"","metadata":{}},{"cell_type":"markdown","source":"## Problem Statement","metadata":{}},{"cell_type":"markdown","source":"Implement a contrastive learning model using PyTorch Geometric to learn meaningful \nrepresentations of 3D point clouds from the ModelNet10 dataset. The model should create \nembeddings where similar shapes are closer in the latent space.\nPlease chek the [original code](https://colab.research.google.com/drive/1oO-Raqge8oGXGNkZQOYTH-je4Xi1SFVI?usp=sharing#scrollTo=J49zjaa5cxRe) and [video](https://youtu.be/XpUKZEGWqbU?si=CpcJurPdDYG0kEGG).","metadata":{}},{"cell_type":"markdown","source":"MAIN TASK (2 points max):\n- Improve baseline loss by:\n  \n  • Increasing the number of epochs (try 30-50)  \n  • Balancing classes (limit samples per class)  \n  • Changing the number of points (now the number of points is set to 512, it can be less or more)  \n  • Adjusting temperature parameter\n  • Using other options\n \n\nBONUS TRACK (2 points max):\n- Implement a classifier by (use one option, please note that the classes are imballanced):\n  \n  • Feature Extraction: Freeze contrastive model + train MLP classifier\n  \n  • Combined a Contrastive and a Classification Loss, please check [pytorch metric learning](https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master)\n  \n  • Pure Classification: Train only classification head","metadata":{}},{"cell_type":"markdown","source":"Install Dependencies","metadata":{}},{"cell_type":"code","source":"import torch\n# !pip install -q torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n!pip install -q pytorch-lightning pytorch-metric-learning plotly clearml","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pytorch_lightning as pl\nfrom torch_geometric.data import Dataset\nfrom torch_geometric.loader import DataLoader\n# from torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import ModelNet\nfrom torch_geometric.nn import MLP, DynamicEdgeConv, global_max_pool\nfrom torch_geometric.transforms import SamplePoints, RandomJitter, RandomFlip, Compose\nfrom pytorch_metric_learning.losses import NTXentLoss\nimport plotly.graph_objects as go\nfrom pathlib import Path\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom clearml import Task\nimport os.path as osp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To configure ClearML in your Colab environment, follow these steps:\n\n---\n\n*Step 1: Create a ClearML Account*\n1. Go to the [ClearML website](https://clear.ml/).\n2. Sign up for a free account if you don’t already have one.\n3. Once registered, log in to your ClearML account.\n\n---\n\n*Step 2: Get Your ClearML Credentials*\n1. After logging in, navigate to the **Settings** page (click on your profile icon in the top-right corner and select **Settings**).\n2. Under the **Workspace** section, find your **+ Create new credentials**.\n3. Copy these credentials for a Jupiter notebook into the code cell below.\n\n---\n\n*Step 3: Accessing the ClearML Dashboard*\n1. Go to your ClearML dashboard (https://app.clear.ml).\n2. Navigate to the **Projects** section to see your experiments.\n3. Click on the experiment (e.g., `Lab_1`) to view detailed metrics, logs, and artifacts.\n\n---","metadata":{}},{"cell_type":"code","source":"#Enter your code here to implement Step 2 of the logging instruction as it is shown below\n%env CLEARML_WEB_HOST=https://app.clear.ml/\n%env CLEARML_API_HOST=https://api.clear.ml\n%env CLEARML_FILES_HOST=https://files.clear.ml\n%env CLEARML_API_ACCESS_KEY=ZP02U03C6V5ER4K9VWRNZT7EWA5ZTV\n%env CLEARML_API_SECRET_KEY=BtA5GXZufr6QGpaqhX1GSKPTvaCt56OLqaNqUGLNoxx2Ye8Ctwbui0Ln5OXVnzUgH4I","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Initialization","metadata":{}},{"cell_type":"code","source":"params = {\n        'lr': 1e-3,\n        'temperature': 0.1,\n        'batch_size': 32,\n        'max_epochs': 5,\n}\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dataset Setup","metadata":{}},{"cell_type":"code","source":"class ModelNet10DataModule(pl.LightningDataModule):\n    CLASS_NAMES = [\n        'bathtub', 'bed', 'chair', 'desk', 'dresser',\n        'monitor', 'night_stand', 'sofa', 'table', 'toilet'\n    ]\n    \n    def __init__(self, batch_size=32, num_points=512):\n        super().__init__()\n        self.batch_size = batch_size\n        self.num_points = num_points\n        self.base_transform = SamplePoints(num_points)\n        self.augmentation = Compose([\n            RandomJitter(0.03),\n            RandomFlip(1)\n        ])\n\n    def prepare_data(self):\n        # Download datasets\n        ModelNet(root='./ModelNet10', name='10', train=True)\n        ModelNet(root='./ModelNet10', name='10', train=False)\n\n    def setup(self, stage=None):\n        self.train_dataset = ModelNet(\n            root='./ModelNet10',\n            name='10',\n            train=True,\n            transform=self.base_transform\n        )\n        self.val_dataset = ModelNet(\n            root='./ModelNet10',\n            name='10',\n            train=False,\n            transform=self.base_transform\n        )\n        \n        print(f\"Training classes: {self.CLASS_NAMES}\")\n        print(f\"Training samples: {len(self.train_dataset)}\")\n        print(f\"Validation samples: {len(self.val_dataset)}\")\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=2\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.val_dataset,\n            batch_size=self.batch_size,\n            num_workers=2\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model Definition","metadata":{}},{"cell_type":"code","source":"class PointCloudContrastive(pl.LightningModule):\n    def __init__(self, params=params, lr=params[\"lr\"], temperature=params[\"temperature\"]):\n        super().__init__()\n        self.save_hyperparameters()\n        self.batch_size = params[\"batch_size\"]\n        \n        # Architecture components\n        self.conv1 = DynamicEdgeConv(MLP([2*3, 64, 64]), k=20, aggr='max')\n        self.conv2 = DynamicEdgeConv(MLP([2*64, 128]), k=20, aggr='max')\n        self.projection_head = MLP([128+64, 256, 128], norm=None)\n        \n        # Loss function\n        self.criterion = NTXentLoss(temperature=temperature)\n\n    def forward(self, data):\n        pos = data.pos.to(self.device)\n        batch = data.batch.to(self.device)\n        \n        x1 = self.conv1(pos, batch)\n        x2 = self.conv2(x1, batch)\n        h_points = self.projection_head(torch.cat([x1, x2], dim=1))\n        return global_max_pool(h_points, batch)\n\n    def training_step(self, batch, batch_idx):\n        aug1, aug2 = self._generate_augmented_views(batch)\n        z1, z2 = self(aug1), self(aug2)\n        loss = self._compute_contrastive_loss(z1, z2)\n        \n        self.log('train_loss', loss, \n                 batch_size=self.batch_size, \n                 prog_bar=True, on_step=True, on_epoch=True)\n        self.log('learning_rate', self.optimizers().param_groups[0]['lr'], \n                on_step=True, on_epoch=False)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        aug1, aug2 = self._generate_augmented_views(batch)\n        z1, z2 = self(aug1), self(aug2)\n        loss = self._compute_contrastive_loss(z1, z2)\n        self.log('val_loss', loss, \n                 batch_size=self.batch_size, \n                 prog_bar=True, on_step=False, on_epoch=True)\n        return loss\n\n    def _generate_augmented_views(self, batch):\n        aug1 = batch.clone()\n        aug1.pos = torch.cat([self.trainer.datamodule.augmentation(d).pos \n                            for d in batch.to_data_list()])\n        aug2 = batch.clone()\n        aug2.pos = torch.cat([self.trainer.datamodule.augmentation(d).pos \n                            for d in batch.to_data_list()])\n        return aug1, aug2\n\n    def _compute_contrastive_loss(self, z1, z2):\n        labels = torch.arange(z1.size(0), device=self.device)\n        return self.criterion(torch.cat([z1, z2]), torch.cat([labels, labels]))\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9)\n        return [optimizer], [scheduler]\n\n    def configure_callbacks(self):\n        return [\n            pl.callbacks.EarlyStopping(\n                monitor='val_loss',\n                patience=10,\n                mode='min',\n                check_on_train_epoch_end=False\n            )\n        ]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Visualization","metadata":{}},{"cell_type":"code","source":"def plot_sample(data, title=\"\"):\n    pos = data.pos.cpu().numpy()\n    label_idx = data.y.item() if hasattr(data, 'y') else 0\n    class_name = ModelNet10DataModule.CLASS_NAMES[label_idx]\n    \n    fig = go.Figure(data=[go.Scatter3d(\n        x=pos[:,0], y=pos[:,1], z=pos[:,2],\n        mode='markers',\n        marker=dict(size=3, opacity=0.8, color=pos[:,2], colorscale='Viridis')\n    )])\n    fig.update_layout(\n        title=f\"{class_name}: {title}\",\n        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n        width=800,\n        height=600\n    )\n    fig.show()\n\ndef check_class_distribution(dataset):\n    class_counts = {name: 0 for name in ModelNet10DataModule.CLASS_NAMES}\n    for data in dataset:\n        class_counts[ModelNet10DataModule.CLASS_NAMES[data.y]] += 1\n    print(\"Class distribution:\")\n    for cls, count in class_counts.items():\n        print(f\"{cls}: {count} samples\")\n\ndef visualize_augmentations(dm):\n    # Get original samples from different classes\n    sample_indices = [\n        next(i for i, d in enumerate(dm.train_dataset) if d.y == class_idx)\n        for class_idx in range(5)  # First 5 classes\n    ]\n    \n    for idx in sample_indices:\n        original = dm.train_dataset[idx]\n        plot_sample(original, \"Original\")\n        \n        # Create augmented version\n        augmented = original.clone()\n        augmented.pos = dm.augmentation(augmented).pos\n        plot_sample(augmented, \"Augmented\")\n        \ndef visualize_embeddings(model, datamodule, device, title=\"\"):\n    model.eval()\n    with torch.no_grad():\n        # Get sample batch and move to device\n        loader = datamodule.train_dataloader()\n        sample = next(iter(loader))\n        sample = sample.to(device)  # Move entire batch to device\n        \n        # Get representations\n        h = model(sample)\n        h = h.cpu().numpy()\n        labels = [datamodule.CLASS_NAMES[y] for y in sample.y.cpu().numpy()]\n\n        # t-SNE dimensionality reduction\n        tsne = TSNE(n_components=2, perplexity=15, random_state=42)\n        h_embedded = tsne.fit_transform(h)\n\n        # Plot\n        plt.figure(figsize=(10, 8))\n        sns.scatterplot(x=h_embedded[:,0], y=h_embedded[:,1], \n                        hue=labels, palette=\"tab10\", alpha=0.7)\n        plt.title(f\"t-SNE Embeddings {title}\")\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n        plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check PyG version\nimport torch_geometric\nprint(torch_geometric.__version__)  # Should be ≥ 2.4.0\n# If version ≥ 2.4.0, you can safely use RandomShear","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Training","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Initialize ClearML Task with proper framework connection\n    task = Task.init(\n        project_name=\"PointCloudContrastiveLearning\",\n        task_name=\"ContrastiveModel_Training\",\n        auto_connect_frameworks={'pytorch': False, \n                                 'tensorflow': False, 'tensorboard': True}\n    )\n    task.connect(params)\n    \n    # Initialize components\n    dm = ModelNet10DataModule(batch_size=params['batch_size'])\n    model = PointCloudContrastive(lr=params['lr'], temperature=params['temperature'])\n\n    logger = pl.loggers.TensorBoardLogger(\n        save_dir=\"logs\",\n        name=\"contrastive_model\",\n        log_graph=True\n    )\n    # Configure trainer\n    trainer = pl.Trainer(\n        max_epochs=params['max_epochs'],\n        accelerator='auto',\n        devices=1,\n        logger=logger,\n        log_every_n_steps=10,\n        callbacks=model.configure_callbacks(),\n    )\n    \n    # Start training\n    dm.setup()\n    model.to(device)\n    visualize_embeddings(model, dm, device, \"(Before Training)\")\n    \n    trainer.fit(model, dm)\n    \n    # Save and log final model\n    torch.save(model.state_dict(), 'contrastive_model.pt')\n    task.upload_artifact('model_weights', 'contrastive_model.pt')\n    task.close()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-29T12:50:01.984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Post-training visualization\nprint(\"\\nAfter training:\")\nvisualize_embeddings(model, dm, device, \"(After Training)\")\n    \n# Save model\ntorch.save(model.state_dict(), 'contrastive_model.pt')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-29T12:50:01.984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Should better output balanced classes\ncheck_class_distribution(dm.train_dataset)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-29T12:50:01.984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Shows matching class labels for original/augmented pairs\nvisualize_augmentations(dm)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-29T12:50:01.984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    # Properly indented validation report\n    val_results = trainer.validate(model, dm.val_dataloader())\n    print(f\"\\nFinal Validation Loss: {val_results[0]['val_loss']:.4f}\")\n    \n    visualize_embeddings(model, dm, device, \"(After Training)\")\n    torch.save(model.state_dict(), 'contrastive_model.pt')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-29T12:50:01.984Z"}},"outputs":[],"execution_count":null}]}